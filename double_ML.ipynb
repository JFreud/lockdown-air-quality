{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = pd.read_csv(\"data/wf.csv\")\n",
    "city_yb = pd.read_csv(\"data/city_yb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = pd.read_csv(\"data/wf.csv\")\n",
    "city_yb = pd.read_csv(\"data/city_yb.csv\")\n",
    "\n",
    "wf[\"temp2\"] = wf[\"temp\"] ** 2\n",
    "wf[\"l_aqi\"] = np.log(1 + wf[\"aqi\"])\n",
    "wf[\"l_pm\"] = np.log(1 + wf[\"pm\"])\n",
    "wf2020 = wf[(wf[\"daynum\"] >= 8401) & (wf[\"daynum\"]<= 8461)].dropna(\n",
    "    subset = ['aqi', 'pm']\n",
    ")\n",
    "wf2020['cities'] = wf2020['city_code'].astype('category')\n",
    "wf2020['days'] = wf2020['daynum'].astype('category')\n",
    "wf2020 = pd.get_dummies(wf2020, drop_first=True)\n",
    "\n",
    "fixed = ['treat']\n",
    "for col in wf2020.columns:\n",
    "    if 'cities' in col or 'days' in col:\n",
    "        fixed.append(col)\n",
    "        \n",
    "weather = ['prec', 'snow', 'temp', 'temp2']\n",
    "out = [\"aqi\", \"l_aqi\", \"pm\", \"l_pm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOUBLE ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated = wf2020[wf2020['treat'] == 1]\n",
    "treated = treated[['daynum', 'city_code']].groupby('city_code')\n",
    "first = treated.apply(lambda x: x.sort_values(by = 'daynum', ascending=True).head(1))\n",
    "\n",
    "day, count = np.unique(first.daynum, return_counts = True)\n",
    "treat_day = day[count == max(count)][0]\n",
    "\n",
    "first = {city:day for day, city in first.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf2020 = wf2020.assign(first = [first.get(city, 0) for city in wf2020['city_code']])\n",
    "group = wf2020[(wf2020['first'] == treat_day) | (wf2020['first'] == 0)]\n",
    "wf2020['first'] = wf2020['first'].astype('category')\n",
    "wf2020 = pd.get_dummies(wf2020, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group['pre'] = group['daynum'] < treat_day\n",
    "group = group.groupby(['city_code', 'pre']).mean().reset_index('pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>prec</th>\n",
       "      <th>snow</th>\n",
       "      <th>temp</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>...</th>\n",
       "      <th>days_8453</th>\n",
       "      <th>days_8454</th>\n",
       "      <th>days_8455</th>\n",
       "      <th>days_8456</th>\n",
       "      <th>days_8457</th>\n",
       "      <th>days_8458</th>\n",
       "      <th>days_8459</th>\n",
       "      <th>days_8460</th>\n",
       "      <th>days_8461</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>False</td>\n",
       "      <td>17973.5</td>\n",
       "      <td>2.020022e+07</td>\n",
       "      <td>12.066931</td>\n",
       "      <td>82.475749</td>\n",
       "      <td>-3.213173</td>\n",
       "      <td>63.077457</td>\n",
       "      <td>1.043483</td>\n",
       "      <td>29.020299</td>\n",
       "      <td>54.381945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>8436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>True</td>\n",
       "      <td>17943.0</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>0.955077</td>\n",
       "      <td>91.424461</td>\n",
       "      <td>-7.415088</td>\n",
       "      <td>110.560652</td>\n",
       "      <td>1.900029</td>\n",
       "      <td>46.410589</td>\n",
       "      <td>34.528697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>False</td>\n",
       "      <td>41679.5</td>\n",
       "      <td>2.020022e+07</td>\n",
       "      <td>19.911129</td>\n",
       "      <td>60.060211</td>\n",
       "      <td>8.265350</td>\n",
       "      <td>52.420406</td>\n",
       "      <td>0.755353</td>\n",
       "      <td>24.584402</td>\n",
       "      <td>58.798611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>True</td>\n",
       "      <td>41649.0</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>26.963940</td>\n",
       "      <td>52.873557</td>\n",
       "      <td>4.507910</td>\n",
       "      <td>90.901378</td>\n",
       "      <td>0.932073</td>\n",
       "      <td>39.604574</td>\n",
       "      <td>43.744799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>False</td>\n",
       "      <td>45630.5</td>\n",
       "      <td>2.020022e+07</td>\n",
       "      <td>17.183897</td>\n",
       "      <td>55.427658</td>\n",
       "      <td>7.256715</td>\n",
       "      <td>74.777778</td>\n",
       "      <td>0.599033</td>\n",
       "      <td>15.702991</td>\n",
       "      <td>60.873931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105012</th>\n",
       "      <td>True</td>\n",
       "      <td>104426.0</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>3.017313</td>\n",
       "      <td>45.966318</td>\n",
       "      <td>8.305754</td>\n",
       "      <td>75.454293</td>\n",
       "      <td>0.904329</td>\n",
       "      <td>24.651155</td>\n",
       "      <td>41.834775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105016</th>\n",
       "      <td>False</td>\n",
       "      <td>131235.5</td>\n",
       "      <td>2.020022e+07</td>\n",
       "      <td>4.517875</td>\n",
       "      <td>49.336072</td>\n",
       "      <td>0.334428</td>\n",
       "      <td>71.642094</td>\n",
       "      <td>0.685550</td>\n",
       "      <td>16.830662</td>\n",
       "      <td>49.696047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105016</th>\n",
       "      <td>True</td>\n",
       "      <td>131205.0</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>14.117087</td>\n",
       "      <td>40.515325</td>\n",
       "      <td>-3.752401</td>\n",
       "      <td>79.599123</td>\n",
       "      <td>0.870514</td>\n",
       "      <td>23.122995</td>\n",
       "      <td>45.691103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105229</th>\n",
       "      <td>False</td>\n",
       "      <td>138259.5</td>\n",
       "      <td>2.020022e+07</td>\n",
       "      <td>354.455191</td>\n",
       "      <td>82.875703</td>\n",
       "      <td>-6.289694</td>\n",
       "      <td>69.260149</td>\n",
       "      <td>0.990021</td>\n",
       "      <td>16.962073</td>\n",
       "      <td>72.094551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105229</th>\n",
       "      <td>True</td>\n",
       "      <td>138229.0</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>453.029360</td>\n",
       "      <td>99.312819</td>\n",
       "      <td>-14.153943</td>\n",
       "      <td>110.584843</td>\n",
       "      <td>1.275185</td>\n",
       "      <td>38.173970</td>\n",
       "      <td>56.382094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 408 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pre  Unnamed: 0          date        prec       snow       temp  \\\n",
       "city_code                                                                      \n",
       "3547       False     17973.5  2.020022e+07   12.066931  82.475749  -3.213173   \n",
       "3547        True     17943.0  2.020013e+07    0.955077  91.424461  -7.415088   \n",
       "4870       False     41679.5  2.020022e+07   19.911129  60.060211   8.265350   \n",
       "4870        True     41649.0  2.020013e+07   26.963940  52.873557   4.507910   \n",
       "4956       False     45630.5  2.020022e+07   17.183897  55.427658   7.256715   \n",
       "...          ...         ...           ...         ...        ...        ...   \n",
       "105012      True    104426.0  2.020013e+07    3.017313  45.966318   8.305754   \n",
       "105016     False    131235.5  2.020022e+07    4.517875  49.336072   0.334428   \n",
       "105016      True    131205.0  2.020013e+07   14.117087  40.515325  -3.752401   \n",
       "105229     False    138259.5  2.020022e+07  354.455191  82.875703  -6.289694   \n",
       "105229      True    138229.0  2.020013e+07  453.029360  99.312819 -14.153943   \n",
       "\n",
       "                  aqi        co        no2         o3  ...  days_8453  \\\n",
       "city_code                                              ...              \n",
       "3547        63.077457  1.043483  29.020299  54.381945  ...   0.038462   \n",
       "3547       110.560652  1.900029  46.410589  34.528697  ...   0.000000   \n",
       "4870        52.420406  0.755353  24.584402  58.798611  ...   0.038462   \n",
       "4870        90.901378  0.932073  39.604574  43.744799  ...   0.000000   \n",
       "4956        74.777778  0.599033  15.702991  60.873931  ...   0.038462   \n",
       "...               ...       ...        ...        ...  ...        ...   \n",
       "105012      75.454293  0.904329  24.651155  41.834775  ...   0.000000   \n",
       "105016      71.642094  0.685550  16.830662  49.696047  ...   0.038462   \n",
       "105016      79.599123  0.870514  23.122995  45.691103  ...   0.000000   \n",
       "105229      69.260149  0.990021  16.962073  72.094551  ...   0.038462   \n",
       "105229     110.584843  1.275185  38.173970  56.382094  ...   0.000000   \n",
       "\n",
       "           days_8454  days_8455  days_8456  days_8457  days_8458  days_8459  \\\n",
       "city_code                                                                     \n",
       "3547        0.038462   0.038462   0.038462   0.038462   0.038462   0.038462   \n",
       "3547        0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4870        0.038462   0.038462   0.038462   0.038462   0.038462   0.038462   \n",
       "4870        0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4956        0.038462   0.038462   0.038462   0.038462   0.038462   0.038462   \n",
       "...              ...        ...        ...        ...        ...        ...   \n",
       "105012      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "105016      0.038462   0.038462   0.038462   0.038462   0.038462   0.038462   \n",
       "105016      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "105229      0.038462   0.038462   0.038462   0.038462   0.038462   0.038462   \n",
       "105229      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "           days_8460  days_8461   first  \n",
       "city_code                                \n",
       "3547        0.038462   0.038462  8436.0  \n",
       "3547        0.000000   0.000000  8436.0  \n",
       "4870        0.038462   0.038462     0.0  \n",
       "4870        0.000000   0.000000     0.0  \n",
       "4956        0.038462   0.038462     0.0  \n",
       "...              ...        ...     ...  \n",
       "105012      0.000000   0.000000     0.0  \n",
       "105016      0.038462   0.038462     0.0  \n",
       "105016      0.000000   0.000000     0.0  \n",
       "105229      0.038462   0.038462     0.0  \n",
       "105229      0.000000   0.000000     0.0  \n",
       "\n",
       "[510 rows x 408 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a83a3c75a0eb>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  compact['Y1-Y0'] = aqi[~group['pre']] - aqi[group['pre']]\n"
     ]
    }
   ],
   "source": [
    "compact = group[~group['pre']]\n",
    "aqi = group['aqi'].values\n",
    "compact['Y1-Y0'] = aqi[~group['pre']] - aqi[group['pre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact = compact.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format this in a manner sympatico with ATT estimation\n",
    "\n",
    "outcome = compact['Y1-Y0']\n",
    "treatment = compact['treat']\n",
    "confounders = compact[weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 778.0728816870247\n",
      "Test MSE of no-covariate model 800.3543552196278\n"
     ]
    }
   ],
   "source": [
    "# specify a model for the conditional expected outcome\n",
    "\n",
    "# TODO(victorveitch) the covariates have basically no predictive power, replace this example with something better\n",
    "\n",
    "# make a function that returns a sklearn model for later use in k-folding\n",
    "def make_Q_model():\n",
    "    return LinearRegression()\n",
    "    return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=100, max_depth=5)\n",
    "Q_model = make_Q_model()\n",
    "\n",
    "# Sanity check that chosen model actually improves test error\n",
    "# A real analysis should give substantial attention to model selection and validation \n",
    "\n",
    "X_w_treatment = confounders.copy()\n",
    "X_w_treatment[\"treatment\"] = treatment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_w_treatment, outcome, test_size=0.2)\n",
    "Q_model.fit(X_train, y_train)\n",
    "y_pred = Q_model.predict(X_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\") \n",
    "baseline_mse=mean_squared_error(y_train.mean()*np.ones_like(y_test), y_test)\n",
    "print(f\"Test MSE of no-covariate model {baseline_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CE of fit model 0.27362737857805364\n",
      "Test CE of no-covariate model 0.27626745079819626\n"
     ]
    }
   ],
   "source": [
    "# specify a model for the propensity score\n",
    "\n",
    "def make_g_model():\n",
    "    return LogisticRegression(max_iter=1000)\n",
    "    return RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=100, max_depth=5)\n",
    "\n",
    "g_model = make_g_model()\n",
    "# Sanity check that chosen model actually improves test error\n",
    "# A real analysis should give substantial attention to model selection and validation \n",
    "\n",
    "X_train, X_test, a_train, a_test = train_test_split(confounders, treatment, test_size=0.2)\n",
    "g_model.fit(X_train, a_train)\n",
    "a_pred = g_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_ce=log_loss(a_test, a_pred)\n",
    "print(f\"Test CE of fit model {test_ce}\") \n",
    "baseline_ce=log_loss(a_test, a_train.mean()*np.ones_like(a_test))\n",
    "print(f\"Test CE of no-covariate model {baseline_ce}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to implement the cross fitting\n",
    "\n",
    "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    \"\"\"\n",
    "    predictions = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, A):\n",
    "        X_train = X.loc[train_index]\n",
    "        A_train = A.loc[train_index]\n",
    "        g = make_model()\n",
    "        g.fit(X_train, A_train)\n",
    "\n",
    "        # get predictions for split\n",
    "        predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    y: array of outcomes\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "\n",
    "    \"\"\"\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_w_treatment = X.copy()\n",
    "    X_w_treatment[\"A\"] = A\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_w_treatment.copy()\n",
    "    X0[\"A\"] = 0\n",
    "    X1 = X_w_treatment.copy()\n",
    "    X1[\"A\"] = 1\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
    "        X_train = X_w_treatment.loc[train_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        q = make_model()\n",
    "        q.fit(X_train, y_train)\n",
    "\n",
    "        if output_type =='binary':\n",
    "            predictions0[test_index] = q.predict_proba(X0.loc[test_index])[:, 1]\n",
    "            predictions1[test_index] = q.predict_proba(X1.loc[test_index])[:, 1]\n",
    "        elif output_type == 'continuous':\n",
    "            predictions0[test_index] = q.predict(X0.loc[test_index])\n",
    "            predictions1[test_index] = q.predict(X1.loc[test_index])\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q0,Q1=outcome_k_fold_fit_and_predict(make_Q_model, X=confounders, y=outcome, A=treatment, n_splits=10, output_type=\"continuous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135846</td>\n",
       "      <td>-24.575467</td>\n",
       "      <td>-41.087033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-47.483196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094061</td>\n",
       "      <td>-17.032831</td>\n",
       "      <td>-34.925517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.480972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100673</td>\n",
       "      <td>-15.995116</td>\n",
       "      <td>-32.506683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-67.323789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.094208</td>\n",
       "      <td>-15.429095</td>\n",
       "      <td>-34.433198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.060072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091899</td>\n",
       "      <td>-25.442115</td>\n",
       "      <td>-43.514097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.856384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          g         Q0         Q1    A          Y\n",
       "0  0.135846 -24.575467 -41.087033  1.0 -47.483196\n",
       "1  0.094061 -17.032831 -34.925517  0.0 -38.480972\n",
       "2  0.100673 -15.995116 -32.506683  0.0 -67.323789\n",
       "3  0.094208 -15.429095 -34.433198  0.0 -37.060072\n",
       "4  0.091899 -25.442115 -43.514097  0.0  -1.856384"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_and_nuisance_estimates = pd.DataFrame({'g': g, 'Q0': Q0, 'Q1': Q1, 'A': treatment, 'Y': outcome})\n",
    "data_and_nuisance_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
    "    \"\"\"\n",
    "    # Double ML estimator for the ATT\n",
    "    This uses the ATT specific scores, see equation 3.9 of https://www.econstor.eu/bitstream/10419/149795/1/869216953.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    if prob_t is None:\n",
    "        prob_t = A.mean() # estimate marginal probability of treatment\n",
    "\n",
    "    tau_hat = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0)).mean()/ prob_t\n",
    "  \n",
    "    scores = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0) - tau_hat*A) / prob_t\n",
    "    n = Y.shape[0] # number of observations\n",
    "    std_hat = np.std(scores) / np.sqrt(n)\n",
    "\n",
    "    return tau_hat, std_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate is -19.319572199026357 pm 11.349616379324026\n"
     ]
    }
   ],
   "source": [
    "tau_hat, std_hat = att_aiptw(**data_and_nuisance_estimates)\n",
    "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.886275852614084"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for comparison, the point estimate without any covariate correction\n",
    "outcome[treatment==1].mean()-outcome[treatment==0].mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a525e117b74db75a0938b9a7ba442b7bcb3e21c3f177debe4c065c7a7c1b83e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
