{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credibility/Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from austen_plots.AustenPlot import AustenPlot\n",
    "\n",
    "from utils.double_ml import *\n",
    "from utils.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametric multiple-time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create week coefficient \n",
    "# treated = wf2020[wf2020['treat'] == 1]\n",
    "# treated = treated[['daynum', 'city_code']].groupby('city_code')\n",
    "# first = treated.apply(lambda x: x.sort_values(by = 'daynum', ascending=True).head(1))\n",
    "# day, count = np.unique(first.daynum, return_counts = True)\n",
    "# treat_day = day[count == max(count)][0]\n",
    "# first = {city:day for day, city in first.values}\n",
    "# wf2020 = wf2020.assign(first = [first.get(city, 0) for city in wf2020['city_code']])\n",
    "# wf2020[\"week_coef\"] = np.floor((wf2020[\"daynum\"] - wf2020[\"first\"])/7).astype(int)\n",
    "\n",
    "# # set -1 lead and untreated to NaN so they don't get week0 dummy\n",
    "# wf2020[\"week_coef\"] = np.where((wf2020[\"week_coef\"] == -1), np.NaN, wf2020[\"week_coef\"])\n",
    "# wf2020[\"week_coef\"][wf2020[\"first\"] == 0] = np.NaN\n",
    "# wf2020[\"week_coef\"] = wf2020[\"week_coef\"].astype('category')\n",
    "# wf2020 = pd.get_dummies(wf2020)\n",
    "\n",
    "# week_coef = []\n",
    "# for col in wf2020.columns:\n",
    "#     if 'week_coef' in col:\n",
    "#         week_coef.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Yname in out:\n",
    "#     Y = wf2020[Yname]\n",
    "#     X = wf2020[fixed + weather + week_coef]\n",
    "#     fit = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "#     print(Yname)\n",
    "#     print(*list(zip([index for index in fit.params.index if 'week_coef' in index],\n",
    "#                     fit.params[[index for index in fit.params.index if 'week_coef' in index]], \n",
    "#                    2*fit.bse[[index for index in fit.params.index if 'week_coef' in index]])), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check parallel trends on two-period subsets (23 and 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E[Y_{t+1} - Y_{t} | A=1, X] - E[Y_{t+1} - Y_{t} | A=0, X] = 0 in all pre-treatment periods t.\n",
    "#  if you've fit a model for Q(a,x) = E[Y_{t+1} - Y_{t} | A=a, x] then you can plot diff(t) = 1/n \\sum_i Q(1,x_i) - Q(0,x_i)\n",
    "\n",
    "\n",
    "\n",
    "# day_23 = day[count == max(count)][0]\n",
    "# wf23 = wf2020[(wf2020['first'] == day_23) | (wf2020['first'] == 0)]\n",
    "\n",
    "# # estimate for each day\n",
    "# day_diffs = []\n",
    "# day_list = np.sort(np.unique(wf23['daynum']))\n",
    "# for d in day_list:\n",
    "#     df = wf23[wf23['daynum'] == d]\n",
    "#     confounders_t = df[['daynum'] + weather + city_fixed + time_fixed]\n",
    "    \n",
    "#     X1 = confounders_t.copy()\n",
    "#     X0 = confounders_t.copy()\n",
    "#     X1[\"treatment\"] = 1\n",
    "#     X0[\"treatment\"] = 0\n",
    "    \n",
    "#     Q0 = Q_model.predict(X0)\n",
    "#     Q1 = Q_model.predict(X1)\n",
    "    \n",
    "#     day_diffs.append(np.mean(Q1 - Q0))\n",
    "\n",
    "# list(zip(day_list, day_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # estimate by week\n",
    "# weeks_list = []\n",
    "# week_diffs = []\n",
    "# for w in week_coef:\n",
    "#     wf23_week = wf23[wf23[w] == 1]\n",
    "#     if len(wf23_week) == 0:\n",
    "#         continue\n",
    "#     confounders_t = wf23_week[['daynum'] + weather + city_fixed + time_fixed]\n",
    "    \n",
    "#     X1 = confounders_t.copy()\n",
    "#     X0 = confounders_t.copy()\n",
    "#     X1[\"treatment\"] = 1\n",
    "#     X0[\"treatment\"] = 0\n",
    "    \n",
    "#     Q0 = Q_model.predict(X0)\n",
    "#     Q1 = Q_model.predict(X1)\n",
    "#     weeks_list.append(w)\n",
    "#     week_diffs.append(np.mean(Q1 - Q0))\n",
    "    \n",
    "# list(zip(weeks_list, week_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_16 = day[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [8436, 8426]\n",
    "Q_models = [LinearRegression, RandomForestRegressor, RandomForestRegressor, XGBRegressor]\n",
    "Q_params = [{}, \n",
    "            {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 10},\n",
    "            {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 3},\n",
    "            {'n_jobs': 1,\n",
    "             'objective': 'reg:squarederror'},\n",
    "           ]\n",
    "g_models = [LogisticRegression, RandomForestClassifier, RandomForestClassifier, XGBClassifier]\n",
    "g_params = [{'max_iter':1000},\n",
    "            {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 10},\n",
    "           {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 3},\n",
    "           {'use_label_encoder': False, \n",
    "            'n_jobs': 1, \n",
    "            'objective': 'binary:logistic', \n",
    "            'eval_metric': 'logloss'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf2020 = make_wf2020()\n",
    "fixed = ['treat']\n",
    "city_fixed = []\n",
    "time_fixed = []\n",
    "for col in wf2020.columns:\n",
    "    if 'cities' in col:\n",
    "        city_fixed.append(col)\n",
    "    if 'days' in col:\n",
    "        time_fixed.append(col)\n",
    "fixed = fixed + city_fixed + time_fixed\n",
    "weather = ['prec', 'snow', 'temp', 'temp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 928.4545363093672 (baseline: 991.8240212613339)\n",
      "Test CE of g model 0.3006517506211365 (baseline: 0.3033059674459485)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 666.0205329913273 (baseline: 991.8240212613339)\n",
      "Test CE of g model 0.4548427116822693 (baseline: 0.3033059674459485)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 717.1066678677829 (baseline: 991.8240212613339)\n",
      "Test CE of g model 0.23440256243323235 (baseline: 0.3033059674459485)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 894.9422331988848 (baseline: 991.8240212613339)\n",
      "Test CE of g model 0.27544953275264206 (baseline: 0.3033059674459485)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.07570071640916463 (baseline: 0.08431496121457412)\n",
      "Test CE of g model 0.3006517506211365 (baseline: 0.3033059674459485)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.04785143154363723 (baseline: 0.08431496121457412)\n",
      "Test CE of g model 0.4548427116822693 (baseline: 0.3033059674459485)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.0526812349684912 (baseline: 0.08431496121457412)\n",
      "Test CE of g model 0.23440256243323235 (baseline: 0.3033059674459485)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.05405543475569606 (baseline: 0.08431496121457412)\n",
      "Test CE of g model 0.27544953275264206 (baseline: 0.3033059674459485)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 421.14989186297873 (baseline: 504.5203559584426)\n",
      "Test CE of g model 0.3006517506211365 (baseline: 0.3033059674459485)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 310.84757125392014 (baseline: 504.5203559584426)\n",
      "Test CE of g model 0.4548427116822693 (baseline: 0.3033059674459485)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 314.855078988778 (baseline: 504.5203559584426)\n",
      "Test CE of g model 0.23440256243323235 (baseline: 0.3033059674459485)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 397.56625633730533 (baseline: 504.5203559584426)\n",
      "Test CE of g model 0.27544953275264206 (baseline: 0.3033059674459485)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.08227930102981673 (baseline: 0.10077920893934493)\n",
      "Test CE of g model 0.3006517506211365 (baseline: 0.3033059674459485)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.04623564664918896 (baseline: 0.10077920893934493)\n",
      "Test CE of g model 0.4548427116822693 (baseline: 0.3033059674459485)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.04912422197766604 (baseline: 0.10077920893934493)\n",
      "Test CE of g model 0.23440256243323235 (baseline: 0.3033059674459485)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.052952160384462196 (baseline: 0.10077920893934493)\n",
      "Test CE of g model 0.27544953275264206 (baseline: 0.3033059674459485)\n"
     ]
    }
   ],
   "source": [
    "out_vars=['aqi', 'l_aqi', 'pm', 'l_pm']\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "for out_var in out_vars:\n",
    "    for i in range(0, len(Q_models)):\n",
    "        print(\"======= \", out_var, \"=======\")\n",
    "        print(\"Day: %d \\n Q: %s \\n g:%s\" % (8436, Q_models[i], g_models[i]))\n",
    "        Q_mse, g_ce, base_mse, base_ce = test_single_models(wf2020, treat_day=8436, outcome_var=out_var, \n",
    "                                            confounder_list=weather,\n",
    "                                            Q_model_class=Q_models[i], Q_model_params=Q_params[i],\n",
    "                                            g_model_class=g_models[i], g_model_params=g_params[i])\n",
    "        print(f\"Test MSE of Q model {Q_mse} (baseline: {base_mse})\") \n",
    "        print(f\"Test CE of g model {g_ce} (baseline: {base_ce})\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 1126.6455008720734 (baseline: 1155.8062584179363)\n",
      "Test CE of g model 0.023324756371169552 (baseline: 0.030056788589195416)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 937.1832603330149 (baseline: 1155.8062584179363)\n",
      "Test CE of g model 0.02350721939805143 (baseline: 0.030056788589195416)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 1066.4395159647668 (baseline: 1155.8062584179363)\n",
      "Test CE of g model 0.027135442661260157 (baseline: 0.030056788589195416)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 885.8037026742313 (baseline: 1155.8062584179363)\n",
      "Test CE of g model 0.023232173678733686 (baseline: 0.030056788589195416)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.138835131746255 (baseline: 0.14601477495339168)\n",
      "Test CE of g model 0.023324756371169552 (baseline: 0.030056788589195416)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.11362400581201956 (baseline: 0.14601477495339168)\n",
      "Test CE of g model 0.02350721939805143 (baseline: 0.030056788589195416)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.1312954027677244 (baseline: 0.14601477495339168)\n",
      "Test CE of g model 0.027135442661260157 (baseline: 0.030056788589195416)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.10133984176314752 (baseline: 0.14601477495339168)\n",
      "Test CE of g model 0.023232173678733686 (baseline: 0.030056788589195416)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 595.8992061030261 (baseline: 624.2022243254472)\n",
      "Test CE of g model 0.023324756371169552 (baseline: 0.030056788589195416)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 483.7834819494898 (baseline: 624.2022243254472)\n",
      "Test CE of g model 0.02350721939805143 (baseline: 0.030056788589195416)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 573.4341418794836 (baseline: 624.2022243254472)\n",
      "Test CE of g model 0.027135442661260157 (baseline: 0.030056788589195416)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 441.993785358717 (baseline: 624.2022243254472)\n",
      "Test CE of g model 0.023232173678733686 (baseline: 0.030056788589195416)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.15723096516636076 (baseline: 0.1731453783069723)\n",
      "Test CE of g model 0.023324756371169552 (baseline: 0.030056788589195416)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.13076824527837103 (baseline: 0.1731453783069723)\n",
      "Test CE of g model 0.02350721939805143 (baseline: 0.030056788589195416)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.15946959973530944 (baseline: 0.1731453783069723)\n",
      "Test CE of g model 0.027135442661260157 (baseline: 0.030056788589195416)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.11207794297152869 (baseline: 0.1731453783069723)\n",
      "Test CE of g model 0.023232173678733686 (baseline: 0.030056788589195416)\n"
     ]
    }
   ],
   "source": [
    "for out_var in out_vars:\n",
    "    for i in range(0, len(Q_models)):\n",
    "        print(\"======= \", out_var, \"=======\")\n",
    "        print(\"Day: %d \\n Q: %s \\n g:%s\" % (8436, Q_models[i], g_models[i]))\n",
    "        Q_mse, g_ce, base_mse, base_ce = test_multi_models(wf2020, outcome_var=out_var, \n",
    "                                            confounder_list=['daynum'] + weather + city_fixed + time_fixed,\n",
    "                                            Q_model_class=Q_models[i], Q_model_params=Q_params[i],\n",
    "                                            g_model_class=g_models[i], g_model_params=g_params[i])\n",
    "        print(f\"Test MSE of Q model {Q_mse} (baseline: {base_mse})\") \n",
    "        print(f\"Test CE of g model {g_ce} (baseline: {base_ce})\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_class",
   "language": "python",
   "name": "nn_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
