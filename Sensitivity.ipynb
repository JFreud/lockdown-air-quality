{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credibility/Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from austen_plots.AustenPlot import AustenPlot\n",
    "\n",
    "from utils.double_ml import *\n",
    "from utils.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametric multiple-time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create week coefficient \n",
    "# treated = wf2020[wf2020['treat'] == 1]\n",
    "# treated = treated[['daynum', 'city_code']].groupby('city_code')\n",
    "# first = treated.apply(lambda x: x.sort_values(by = 'daynum', ascending=True).head(1))\n",
    "# day, count = np.unique(first.daynum, return_counts = True)\n",
    "# treat_day = day[count == max(count)][0]\n",
    "# first = {city:day for day, city in first.values}\n",
    "# wf2020 = wf2020.assign(first = [first.get(city, 0) for city in wf2020['city_code']])\n",
    "# wf2020[\"week_coef\"] = np.floor((wf2020[\"daynum\"] - wf2020[\"first\"])/7).astype(int)\n",
    "\n",
    "# # set -1 lead and untreated to NaN so they don't get week0 dummy\n",
    "# wf2020[\"week_coef\"] = np.where((wf2020[\"week_coef\"] == -1), np.NaN, wf2020[\"week_coef\"])\n",
    "# wf2020[\"week_coef\"][wf2020[\"first\"] == 0] = np.NaN\n",
    "# wf2020[\"week_coef\"] = wf2020[\"week_coef\"].astype('category')\n",
    "# wf2020 = pd.get_dummies(wf2020)\n",
    "\n",
    "# week_coef = []\n",
    "# for col in wf2020.columns:\n",
    "#     if 'week_coef' in col:\n",
    "#         week_coef.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Yname in out:\n",
    "#     Y = wf2020[Yname]\n",
    "#     X = wf2020[fixed + weather + week_coef]\n",
    "#     fit = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "#     print(Yname)\n",
    "#     print(*list(zip([index for index in fit.params.index if 'week_coef' in index],\n",
    "#                     fit.params[[index for index in fit.params.index if 'week_coef' in index]], \n",
    "#                    2*fit.bse[[index for index in fit.params.index if 'week_coef' in index]])), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check parallel trends on two-period subsets (23 and 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E[Y_{t+1} - Y_{t} | A=1, X] - E[Y_{t+1} - Y_{t} | A=0, X] = 0 in all pre-treatment periods t.\n",
    "#  if you've fit a model for Q(a,x) = E[Y_{t+1} - Y_{t} | A=a, x] then you can plot diff(t) = 1/n \\sum_i Q(1,x_i) - Q(0,x_i)\n",
    "\n",
    "\n",
    "\n",
    "# day_23 = day[count == max(count)][0]\n",
    "# wf23 = wf2020[(wf2020['first'] == day_23) | (wf2020['first'] == 0)]\n",
    "\n",
    "# # estimate for each day\n",
    "# day_diffs = []\n",
    "# day_list = np.sort(np.unique(wf23['daynum']))\n",
    "# for d in day_list:\n",
    "#     df = wf23[wf23['daynum'] == d]\n",
    "#     confounders_t = df[['daynum'] + weather + city_fixed + time_fixed]\n",
    "    \n",
    "#     X1 = confounders_t.copy()\n",
    "#     X0 = confounders_t.copy()\n",
    "#     X1[\"treatment\"] = 1\n",
    "#     X0[\"treatment\"] = 0\n",
    "    \n",
    "#     Q0 = Q_model.predict(X0)\n",
    "#     Q1 = Q_model.predict(X1)\n",
    "    \n",
    "#     day_diffs.append(np.mean(Q1 - Q0))\n",
    "\n",
    "# list(zip(day_list, day_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # estimate by week\n",
    "# weeks_list = []\n",
    "# week_diffs = []\n",
    "# for w in week_coef:\n",
    "#     wf23_week = wf23[wf23[w] == 1]\n",
    "#     if len(wf23_week) == 0:\n",
    "#         continue\n",
    "#     confounders_t = wf23_week[['daynum'] + weather + city_fixed + time_fixed]\n",
    "    \n",
    "#     X1 = confounders_t.copy()\n",
    "#     X0 = confounders_t.copy()\n",
    "#     X1[\"treatment\"] = 1\n",
    "#     X0[\"treatment\"] = 0\n",
    "    \n",
    "#     Q0 = Q_model.predict(X0)\n",
    "#     Q1 = Q_model.predict(X1)\n",
    "#     weeks_list.append(w)\n",
    "#     week_diffs.append(np.mean(Q1 - Q0))\n",
    "    \n",
    "# list(zip(weeks_list, week_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_16 = day[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [8436, 8426]\n",
    "Q_models = [LinearRegression, RandomForestRegressor, RandomForestRegressor, XGBRegressor]\n",
    "Q_params = [{}, \n",
    "            {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 10},\n",
    "            {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 3},\n",
    "            {'n_jobs': 1,\n",
    "             'objective': 'reg:squarederror'},\n",
    "           ]\n",
    "g_models = [LogisticRegression, RandomForestClassifier, RandomForestClassifier, XGBClassifier]\n",
    "g_params = [{'max_iter':1000},\n",
    "            {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 10},\n",
    "           {'random_state': RANDOM_SEED,\n",
    "                            'n_estimators': 100,\n",
    "                            'max_depth': 3},\n",
    "           {'use_label_encoder': False, \n",
    "            'n_jobs': 1, \n",
    "            'objective': 'binary:logistic', \n",
    "            'eval_metric': 'logloss'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf2020 = make_wf2020(city_var=True)\n",
    "fixed = ['treat']\n",
    "city_fixed = []\n",
    "time_fixed = []\n",
    "for col in wf2020.columns:\n",
    "    if 'cities' in col:\n",
    "        city_fixed.append(col)\n",
    "    if 'days' in col:\n",
    "        time_fixed.append(col)\n",
    "fixed = fixed + city_fixed + time_fixed\n",
    "weather = ['prec', 'snow', 'temp', 'temp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 576.1978034468505 (baseline: 699.1674968233232)\n",
      "Test CE of g model 0.44755860554680627 (baseline: 0.35605301696375635)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 389.3823480507066 (baseline: 699.1674968233232)\n",
      "Test CE of g model 0.2305590746260858 (baseline: 0.35605301696375635)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 418.2147286782791 (baseline: 699.1674968233232)\n",
      "Test CE of g model 0.257838127319458 (baseline: 0.35605301696375635)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 355.48537018585813 (baseline: 699.1674968233232)\n",
      "Test CE of g model 0.25563285139655 (baseline: 0.35605301696375635)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.05537131044956074 (baseline: 0.06721103985183191)\n",
      "Test CE of g model 0.44755860554680627 (baseline: 0.35605301696375635)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.032768001808287386 (baseline: 0.06721103985183191)\n",
      "Test CE of g model 0.2305590746260858 (baseline: 0.35605301696375635)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.037398899888129764 (baseline: 0.06721103985183191)\n",
      "Test CE of g model 0.257838127319458 (baseline: 0.35605301696375635)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.032108306891587904 (baseline: 0.06721103985183191)\n",
      "Test CE of g model 0.25563285139655 (baseline: 0.35605301696375635)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 368.3102392310831 (baseline: 475.67516656672825)\n",
      "Test CE of g model 0.44755860554680627 (baseline: 0.35605301696375635)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 264.2194960614924 (baseline: 475.67516656672825)\n",
      "Test CE of g model 0.2305590746260858 (baseline: 0.35605301696375635)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 283.6001316490459 (baseline: 475.67516656672825)\n",
      "Test CE of g model 0.257838127319458 (baseline: 0.35605301696375635)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 260.8750916488792 (baseline: 475.67516656672825)\n",
      "Test CE of g model 0.25563285139655 (baseline: 0.35605301696375635)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.0669845480460012 (baseline: 0.08620138681126338)\n",
      "Test CE of g model 0.44755860554680627 (baseline: 0.35605301696375635)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.03958495026071971 (baseline: 0.08620138681126338)\n",
      "Test CE of g model 0.2305590746260858 (baseline: 0.35605301696375635)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.043008870932792855 (baseline: 0.08620138681126338)\n",
      "Test CE of g model 0.257838127319458 (baseline: 0.35605301696375635)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.041126094465065405 (baseline: 0.08620138681126338)\n",
      "Test CE of g model 0.25563285139655 (baseline: 0.35605301696375635)\n"
     ]
    }
   ],
   "source": [
    "out_vars=['aqi', 'l_aqi', 'pm', 'l_pm']\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "city_economic = ['pop_city', 'gdp_city', 'firm_city']\n",
    "city_environmental = ['gonglu', 'emit_ww', 'emit_so1', 'emi_dust1']\n",
    "\n",
    "for out_var in out_vars:\n",
    "    for i in range(0, len(Q_models)):\n",
    "        print(\"======= \", out_var, \"=======\")\n",
    "        print(\"Day: %d \\n Q: %s \\n g:%s\" % (8436, Q_models[i], g_models[i]))\n",
    "        Q_mse, g_ce, base_mse, base_ce = test_single_models(wf2020, treat_day=8436, outcome_var=out_var, \n",
    "                                            confounder_list=weather + city_economic + city_environmental,\n",
    "                                            Q_model_class=Q_models[i], Q_model_params=Q_params[i],\n",
    "                                            g_model_class=g_models[i], g_model_params=g_params[i])\n",
    "        print(f\"Test MSE of Q model {Q_mse} (baseline: {base_mse})\") \n",
    "        print(f\"Test CE of g model {g_ce} (baseline: {base_ce})\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 1246.0233743347035 (baseline: 1267.4557211139256)\n",
      "Test CE of g model 0.03452923657882198 (baseline: 0.03461569231859753)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 964.0175685640764 (baseline: 1267.4557211139256)\n",
      "Test CE of g model 0.056948469799316295 (baseline: 0.03461569231859753)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 1177.6943868847477 (baseline: 1267.4557211139256)\n",
      "Test CE of g model 0.03088453789612522 (baseline: 0.03461569231859753)\n",
      "=======  aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 1031.4616947347013 (baseline: 1267.4557211139256)\n",
      "Test CE of g model 0.0306813044789001 (baseline: 0.03461569231859753)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.1513462177913453 (baseline: 0.15702037035384436)\n",
      "Test CE of g model 0.03452923657882198 (baseline: 0.03461569231859753)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.11710630082672394 (baseline: 0.15702037035384436)\n",
      "Test CE of g model 0.056948469799316295 (baseline: 0.03461569231859753)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.14216632135260152 (baseline: 0.15702037035384436)\n",
      "Test CE of g model 0.03088453789612522 (baseline: 0.03461569231859753)\n",
      "=======  l_aqi =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.11810022374489777 (baseline: 0.15702037035384436)\n",
      "Test CE of g model 0.0306813044789001 (baseline: 0.03461569231859753)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 690.7176687563203 (baseline: 702.4451881181408)\n",
      "Test CE of g model 0.03452923657882198 (baseline: 0.03461569231859753)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 484.60038622885884 (baseline: 702.4451881181408)\n",
      "Test CE of g model 0.056948469799316295 (baseline: 0.03461569231859753)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 650.1842933566502 (baseline: 702.4451881181408)\n",
      "Test CE of g model 0.03088453789612522 (baseline: 0.03461569231859753)\n",
      "=======  pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 531.7479034465638 (baseline: 702.4451881181408)\n",
      "Test CE of g model 0.0306813044789001 (baseline: 0.03461569231859753)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.linear_model._base.LinearRegression'> \n",
      " g:<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Test MSE of Q model 0.1805619768902929 (baseline: 0.18612666959742888)\n",
      "Test CE of g model 0.03452923657882198 (baseline: 0.03461569231859753)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.1267621085854846 (baseline: 0.18612666959742888)\n",
      "Test CE of g model 0.056948469799316295 (baseline: 0.03461569231859753)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'sklearn.ensemble._forest.RandomForestRegressor'> \n",
      " g:<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Test MSE of Q model 0.17189801097379864 (baseline: 0.18612666959742888)\n",
      "Test CE of g model 0.03088453789612522 (baseline: 0.03461569231859753)\n",
      "=======  l_pm =======\n",
      "Day: 8436 \n",
      " Q: <class 'xgboost.sklearn.XGBRegressor'> \n",
      " g:<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Test MSE of Q model 0.13065129539333356 (baseline: 0.18612666959742888)\n",
      "Test CE of g model 0.0306813044789001 (baseline: 0.03461569231859753)\n"
     ]
    }
   ],
   "source": [
    "for out_var in out_vars:\n",
    "    for i in range(0, len(Q_models)):\n",
    "        print(\"======= \", out_var, \"=======\")\n",
    "        print(\"Day: %d \\n Q: %s \\n g:%s\" % (8436, Q_models[i], g_models[i]))\n",
    "        Q_mse, g_ce, base_mse, base_ce = test_multi_models(wf2020, outcome_var=out_var, \n",
    "                                            confounder_list=['daynum'] + weather + city_economic + city_environmental,\n",
    "                                            Q_model_class=Q_models[i], Q_model_params=Q_params[i],\n",
    "                                            g_model_class=g_models[i], g_model_params=g_params[i])\n",
    "        print(f\"Test MSE of Q model {Q_mse} (baseline: {base_mse})\")\n",
    "        print(f\"Test CE of g model {g_ce} (baseline: {base_ce})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_class",
   "language": "python",
   "name": "nn_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
